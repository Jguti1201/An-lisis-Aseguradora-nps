# An-lisis-Aseguradora-nps
ğŸ“Œ DescripciÃ³n del proyecto
Este proyecto corresponde al anÃ¡lisis de datos de siniestros y encuestas NPS de una aseguradora, integrando ambas fuentes con el fin de:

Limpiar y preparar los datos para modelado.
Explorar la distribuciÃ³n del indicador NPS (nps100).
Seleccionar variables relevantes que expliquen la satisfacciÃ³n del cliente.
Entrenar modelos de clasificaciÃ³n (Random Forest, RegresiÃ³n LogÃ­stica, etc.).
Realizar visualizaciones descriptivas y anÃ¡lisis estadÃ­stico.

El trabajo se ha realizado en Python dentro de un Jupyter Notebook, cuya exportaciÃ³n generÃ³ el archivo HTML proporcionado.

ğŸ“‚ Estructura del proyecto
.
â”œâ”€â”€ Analisis Mapfre Brasil.html    # ExportaciÃ³n del notebook con todo el anÃ¡lisis
â”œâ”€â”€ BBDD Siniestro - consolidado - definitivo.xlsx
â”œâ”€â”€ Encuestas corregidas 2021-2022.xlsx
â””â”€â”€ README.md                      # Este archivo


ğŸ“Š Dataset utilizado
1. Base de siniestros
Archivo: BBDD Siniestro - consolidado - definitivo.xlsx
Contiene informaciÃ³n operacional de siniestros, incluyendo:

Fechas (ocurrencia, tÃ©rmino).
Importes.
Duraciones.
Datos de pÃ³lizas.
Clasificaciones internas.

2. Base de encuestas
Archivo: Encuestas corregidas 2021-2022.xlsx
Incluye:

InformaciÃ³n de encuestas posterior al siniestro.
Indicador NPS (nps100) con valores:

100 â†’ Promotor
0 â†’ Pasivo
-100 â†’ Detractor



DistribuciÃ³n encontrada:

100 â†’ 68.89%
-100 â†’ 18.36%
0 â†’ 12.75%


ğŸ§¹ Limpieza y preparaciÃ³n de datos
En el anÃ¡lisis se ejecutaron tareas clave como:

EliminaciÃ³n de columnas irrelevantes o duplicadas:

"nps100", "ID da pesquisa", "ID da transaÃ§Ã£o" de encuestas.
Columnas equivalentes en siniestros.


Reemplazo de valores no vÃ¡lidos (e.g., reemplazo de "." en fechas).
EliminaciÃ³n de "ID TransacciÃ³n", "IDPoliza".
UniÃ³n de ambas bases por identificadores comunes.
EliminaciÃ³n de filas sin valor en el target nps100.


ğŸ” AnÃ¡lisis exploratorio (EDA)
Incluye:

EstadÃ­sticos descriptivos.
Histogramas y distribuciones.
AnÃ¡lisis de correlaciÃ³n.
DetecciÃ³n de variables redundantes o con baja variabilidad.
ConversiÃ³n de variables datetime.
CodificaciÃ³n del target (Label Encoding):
0 â†’ 100.0
1 â†’ -100.0
2 â†’ 0.0




ğŸ§  Feature Selection
Se empleÃ³ la librerÃ­a featurewiz con:
Pythonfeaturewiz(df, target="nps100", corr_limit=0.7)Mostrar mÃ¡s lÃ­neas
Resultados destacados:

EliminaciÃ³n de 13 variables ID o sin relevancia.
EliminaciÃ³n de 15 variables altamente correlacionadas.
Dataset final con 99 variables explicativas.


ğŸ¤– Modelos entrenados
âœ” RandomForestClassifier

Entrenamiento con train_test_split.
EvaluaciÃ³n: accuracy general del modelo.
AnÃ¡lisis de importancias.

âœ” LogisticRegression

ComparaciÃ³n con baseline.
MÃ¡s interpretable que Random Forest.


ğŸ“ˆ VisualizaciÃ³n
El proyecto utiliza:

Matplotlib
Seaborn (theme ggplot)
Configuraciones globales:
Pythonplt.rcParams['image.cmap'] = "bwr"plt.rcParams['savefig.bbox'] = "tight"Mostrar mÃ¡s lÃ­neas



ğŸ“¦ LibrerÃ­as utilizadas
InstalaciÃ³n recomendada
Shellpip install numpy pandas seaborn matplotlib scikit-learn featurewiz fitterMostrar mÃ¡s lÃ­neas
LibrerÃ­as detectadas en el anÃ¡lisis

numpy
pandas
matplotlib
seaborn
scikit-learn

neighbors
model_selection
ensemble
metrics
linear_model


featurewiz
fitter
random
itertools
multiprocessing


â–¶ CÃ³mo ejecutar el anÃ¡lisis

Abrir Jupyter Notebook:
Shelljupyter notebookMostrar mÃ¡s lÃ­neas

Cargar el archivo fuente del anÃ¡lisis (versiÃ³n .ipynb del HTML).
Asegurar que los archivos Excel estÃ©n en la misma carpeta.
Ejecutar las celdas en orden.


ğŸ“ Licencia
El archivo HTML contiene estilos y estructuras de JupyterLab bajo licencia Modified BSD License (Jupyter Development Team, 2014â€“2017).
